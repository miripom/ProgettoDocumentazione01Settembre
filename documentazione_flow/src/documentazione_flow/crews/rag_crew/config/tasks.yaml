analyze_and_generate_questions_task:
  description: >
    PHASE 1: COMPREHENSIVE ANALYSIS AND TARGETED QUESTION GENERATION
    
    Your task is to systematically analyze the EU AI Act documentation template and use RAG search to identify
    exactly what information is available versus what needs to be collected from the user.
    
    For the application "{application_name}", perform the following systematic analysis:
    
    1. **RAG INFORMATION EXTRACTION** - Search for information in ALL areas including:
       - Application owner and contact information: "Who is the application owner? What are their contact details?"
       - Document versioning and reviewers: "What is the document version? Who are the reviewers?"
       - Repository and deployment links: "What is the GitHub repository? What are the deployment links?"
       - Architecture and technical specifications: "What is the system architecture? What technologies are used?"
       - Models and algorithms: "What AI models are implemented? What datasets are used?"
       - Deployment and infrastructure: "How is the system deployed? What cloud services are used?"
       - Risk management: "What are the identified risks? What mitigation measures exist?"
       - Testing and validation: "What testing has been performed? What are the accuracy metrics?"
       - Human oversight: "What human oversight mechanisms exist? How are interventions handled?"
       - Compliance measures: "What compliance measures are implemented? What standards are followed?"
    
    2. **DETAILED SECTION ANALYSIS** - For each major documentation section, identify:
       - What specific information was found in RAG search
       - What critical details are missing
       - What user input is required
    
    3. **TARGETED QUESTION GENERATION** - Create specific, detailed questions for ALL missing information:
       
       **1. Application Documentation Template:**
       - "What is the full name of the application owner?"
       - "What is the email address of the application owner?"
       - "What is the phone number of the application owner?"
       - "What department/organization owns this application?"
       - "What is the current document version number?"
       - "What is the last updated date for this documentation?"
       - "What changes were made in this version (change log)?"
       - "Who is the technical reviewer for this application?"
       - "Who is the legal/compliance reviewer?"
       - "Who is the security reviewer?"
       - "Who is the business stakeholder reviewer?"
       
       **2. Key Links:**
       - "What is the complete GitHub repository URL?"
       - "What is the main branch name being used?"
       - "What are the repository access permissions?"
       - "What CI/CD platform is being used (GitHub Actions, Azure DevOps, etc.)?"
       - "What is the deployment pipeline URL?"
       - "What deployment environments are configured (dev, staging, prod)?"
       - "Where is the API documentation located (Swagger URL)?"
       - "What is the current API version?"
       - "What authentication methods are used for the API?"
       - "What is the Azure subscription ID or cloud account details?"
       - "What is the resource group name?"
       - "What Azure region is being used?"
       - "What project management platform is used (Jira, Azure DevOps, etc.)?"
       - "What is the project board URL?"
       - "What is the epic name for this project?"
       - "Where is the application architecture diagram located?"
       - "What is the complete technology stack?"
       - "What deployment model is used?"
       
       **3. Purpose and Intended Use:**
       - "What is the specific purpose of this AI system?"
       - "What problem does this AI application solve?"
       - "Who are the target users and stakeholders?"
       - "What are the measurable goals and KPIs?"
       - "What ethical considerations have been identified?"
       - "What are the prohibited uses of this system?"
       - "What is the operational environment?"
       
       **4. EU AI Act Risk Classification:**
       - "What is the EU AI Act risk classification (High/Limited/Minimal)?"
       - "What is the justification for this risk classification?"
       - "What compliance measures are required?"
       - "What high-risk categories are excluded?"
       
       **5. Application Functionality:**
       - "What can the AI model do (capabilities)?"
       - "What cannot the AI model do (limitations)?"
       - "What input data formats are supported?"
       - "What are examples of valid inputs?"
       - "How should the system outputs be interpreted?"
       - "What is the detailed system architecture?"
       
       **6. Models and Datasets:**
       - "What AI models are used (names, versions, providers)?"
       - "Where is the documentation for each model?"
       - "What datasets are used for training and evaluation?"
       - "Where is the documentation for each dataset?"
       
       **7. Deployment:**
       - "What is the infrastructure setup (VMs, containers, etc.)?"
       - "What cloud services are specifically used?"
       - "What external systems are integrated?"
       - "What are the API endpoints and authentication methods?"
       - "What is the deployment and rollback strategy?"
       
       **8. Lifecycle Management:**
       - "What monitoring procedures are in place?"
       - "What performance metrics are tracked?"
       - "How is versioning and change management handled?"
       - "What are the update and maintenance procedures?"
       
       **9. Risk Management:**
       - "What risk assessment methodology is used?"
       - "What specific risks have been identified?"
       - "What risk mitigation measures are implemented?"
       - "What preventive and protective measures exist?"
       
       **10. Testing and Validation:**
       - "What accuracy testing has been performed?"
       - "What are the specific accuracy metrics and results?"
       - "What data quality procedures are in place?"
       - "What robustness testing has been conducted?"
       - "What cybersecurity measures are implemented?"
       
       **11. Human Oversight:**
       - "What human-in-the-loop mechanisms exist?"
       - "What override and intervention procedures are available?"
       - "What user training and instructions are provided?"
       - "What are the system limitations and constraints?"
       
       **12. Incident Management:**
       - "What common issues have been identified?"
       - "What troubleshooting procedures exist?"
       - "What are the support contact details?"
       - "What escalation procedures are defined?"
       
       **13. EU Declaration of Conformity:**
       - "What standards are applied for compliance?"
       - "What documentation metadata is required?"
    
    EXPECTED OUTPUT FORMAT:
    ```
    # RAG SEARCH ANALYSIS REPORT
    
    ## INFORMATION FOUND IN EXISTING DOCUMENTATION:
    [Detailed summary of what was found for each section]
    
    ## CRITICAL INFORMATION GAPS IDENTIFIED:
    [List of missing information organized by documentation section]
    
    ## TARGETED QUESTIONS FOR USER INPUT:
    [Organized list of specific questions grouped by documentation section - include ALL sections from 1-13]
    
    ## RECOMMENDED INFORMATION COLLECTION STRATEGY:
    [Priority order for collecting missing information]
    ```
    
    Application name: {application_name}
    
  expected_output: >
    A comprehensive analysis report containing:
    - Complete RAG search results organized by documentation section
    - Detailed identification of information gaps
    - Targeted, specific questions for user input organized by priority
    - Clear mapping between questions and documentation template sections
    - Strategic approach for information collection
  agent: documentation_question_generator

compile_complete_documentation_task:
  description: >
    PHASE 2: DOCUMENTATION COMPILATION AND ASSEMBLY
    
    Using the analysis from Phase 1 and collecting any missing information from the user, compile the complete
    EU AI Act compliant documentation for "{application_name}".
    
    **DOCUMENTATION STRUCTURE TO FOLLOW:**
    
    1. **Application Documentation Template** (Header section)
       - Application Owner (Name, Email, Phone, Department)
       - Document Version (Version, Last Updated, Change Log)
       - Reviewers (Technical, Legal, Security, Business)
    
    2. **Key Links**
       - Code Repository (GitHub URL, Branch, Access)
       - Deployment Pipeline (CI/CD Platform, Pipeline URL, Environment)
       - API Documentation (Swagger Docs, API Version, Authentication)
       - Cloud Account (Provider, Subscription, Resource Group, Region)
       - Project Management Board (Platform, Board URL, Epic)
       - Application Architecture (Diagram, Technology Stack, Deployment Model)
    
    3. **Purpose and Intended Use**
       - AI System Purpose Description
       - Problem the AI Application Aims to Solve
       - Target Users and Stakeholders
       - Measurable Goals and KPIs
       - Ethical Considerations and Regulatory Constraints
       - Clear Statement on Prohibited Uses
       - Operational Environment
    
    4. **EU AI Act Risk Classification**
       - Risk classification with detailed justification
       - Required compliance measures
       - Excluded high-risk categories
    
    5. **Application Functionality**
       - Instructions for Use for Deployers (EU AI Act Article 13)
       - Model Capabilities and Limitations
       - Input Data Requirements and Examples
       - Output Explanation and Interpretation
       - System Architecture Overview
    
    6. **Models and Datasets**
       - Complete model documentation table
       - Dataset documentation table
       - Links to Single Source of Truth for each
    
    7. **Deployment**
       - Infrastructure and Environment Details
       - Integration with External Systems
       - Deployment Plan
    
    8. **Lifecycle Management**
       - Monitoring Procedures
       - Metrics and KPIs
       - Key Activities
       - Documentation Requirements
    
    9. **Risk Management System**
       - Risk Assessment Methodology
       - Identified Risks
       - Risk Mitigation Measures
    
    10. **Testing and Validation**
        - Accuracy Testing
        - Data Quality and Management
        - Robustness Measures
        - Cybersecurity
    
    11. **Human Oversight**
        - Human-in-the-Loop Mechanisms
        - Override and Intervention Procedures
        - User Instructions and Training
        - System Limitations and Constraints
    
    12. **Incident Management**
        - Common Issues and Solutions
        - Support Contact
    
    13. **EU Declaration of Conformity**
        - Standards Applied
        - Documentation Metadata
    
    **COMPILATION INSTRUCTIONS:**
    
    1. **Use RAG Information**: Integrate all information found through RAG search
    2. **Collect Missing Information**: Use the user input tools to gather required details
    3. **Maintain Template Structure**: Follow the exact structure and formatting of the template
    4. **Ensure Completeness**: Every section must be populated or marked as requiring additional input
    5. **Professional Formatting**: Use proper Markdown formatting with tables, headers, and lists
    6. **Compliance Focus**: Ensure all EU AI Act requirements are addressed
    
    **FOR MISSING INFORMATION:**
    - Use collect_missing_information tool to gather user input
    - Write exactly what the user provide in input
    - Maintain professional document flow even with placeholders
    
    Application name: {application_name}
    
  expected_output: >
    A complete, professional EU AI Act compliant documentation document in markdown format that includes:
    - All required sections properly populated with available information
    - User-provided information seamlessly integrated
    - Clear placeholders for any remaining missing information
    - Professional formatting matching the template structure
    - Complete compliance with EU AI Act documentation requirements
    - Ready-to-use documentation that follows the exact template format
  agent: documentation_compiler
  context:
    - analyze_and_generate_questions_task
